{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copia de Glove 2 P3-MovieGenrePrediction CA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ggQ-AQ3Glvos"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yquA413pTgG",
        "colab_type": "text"
      },
      "source": [
        "# Project 3\n",
        "\n",
        "\n",
        "# Movie Genre Classification\n",
        "\n",
        "Classify a movie genre based on its plot.\n",
        "\n",
        "<img src=\"https://github.com/albahnsen/AdvancedMethodsDataAnalysisClass/blob/master/Exercises/moviegenre.png?raw=1\"\n",
        "     style=\"float: left; margin-right: 10px;\" />\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://www.kaggle.com/c/miia4201-202019-p3-moviegenreclassification/overview\n",
        "\n",
        "### Data\n",
        "\n",
        "Input:\n",
        "- movie plot\n",
        "\n",
        "Output:\n",
        "Probability of the movie belong to each genre\n",
        "\n",
        "\n",
        "### Evaluation\n",
        "\n",
        "- 20% API\n",
        "- 30% Report with all the details of the solution, the analysis and the conclusions. The report cannot exceed 10 pages, must be send in PDF format and must be self-contained.\n",
        "- 50% Performance in the Kaggle competition (The grade for each group will be proportional to the ranking it occupies in the competition. The group in the first place will obtain 5 points, for each position below, 0.25 points will be subtracted, that is: first place: 5 points, second: 4.75 points, third place: 4.50 points ... eleventh place: 2.50 points, twelfth place: 2.25 points).\n",
        "\n",
        "• The project must be carried out in the groups assigned for module 4.\n",
        "• Use clear and rigorous procedures.\n",
        "• The delivery of the project is on July 12, 2020, 11:59 pm, through Sicua + (Upload: the API and the report in PDF format).\n",
        "• No projects will be received after the delivery time or by any other means than the one established. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Acknowledgements\n",
        "\n",
        "We thank Professor Fabio Gonzalez, Ph.D. and his student John Arevalo for providing this dataset.\n",
        "\n",
        "See https://arxiv.org/abs/1702.01992"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN8JE9Uiwuee",
        "colab_type": "text"
      },
      "source": [
        "# TRANSFORMACIÓN DATOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoMQkcHW05vP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c594a32b-4c3b-43d1-ea01-bdb06fa1e2ba"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORtav20olRMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.metrics import r2_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import nltk\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7PEyIzJ1o-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyGTaPLbzzru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "626e79f5-ccbe-4088-92e1-613b64c83e24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex7zEQRG4LSs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ab063c08-f37c-41c4-c6d8-dce450a74518"
      },
      "source": [
        "# first, build index mapping words in the embeddings set\n",
        "# to their embedding vector\n",
        "\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/My Drive//glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-cYgpChk9oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTraining = pd.read_csv('https://github.com/albahnsen/AdvancedMethodsDataAnalysisClass/raw/master/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
        "dataTesting = pd.read_csv('https://github.com/albahnsen/AdvancedMethodsDataAnalysisClass/raw/master/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Q2rsLFJMg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTraining[\"plot_vf\"] = dataTraining.iloc[:,1].map(str) + \" \" + dataTraining.iloc[:,2].map(str)\n",
        "dataTesting[\"plot_vf\"] = dataTesting.iloc[:,1].map(str) + \" \" + dataTesting.iloc[:,2].map(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9s0lo-Zwuvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "9a216b16-3e6e-49d5-c11c-baeb307b2fc3"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5nGQTOxvX3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "def lematizacion(text):\n",
        "  lmtzr = WordNetLemmatizer()\n",
        "  VERB_CODES = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}\n",
        "  ADJ_CODES = {'JJ','JJR','JJS'}\n",
        "  ADV_CODES = {'RB','RBR','RBS'}\n",
        "  NOUN_CODES = {'NN', 'NNP','NNS','NNPS'}\n",
        "  new_text = []\n",
        "  words = nltk.word_tokenize(text)\n",
        "  role = nltk.pos_tag(words)\n",
        "  \n",
        "  for i,word in enumerate(words):\n",
        "    if role[i][1] in VERB_CODES:\n",
        "      new_word = lmtzr.lemmatize(word, 'v')\n",
        "      #x =  TreebankWordDetokenizer().detokenize(new_word)\n",
        "    else:\n",
        "      if role[i][1] in ADJ_CODES:\n",
        "        new_word = lmtzr.lemmatize(word, 'a')\n",
        "        #x =  TreebankWordDetokenizer().detokenize(new_word)\n",
        "      else:\n",
        "        if role[i][1] in ADV_CODES:\n",
        "          new_word = lmtzr.lemmatize(word, 'r')\n",
        "          #x =  TreebankWordDetokenizer().detokenize(new_word)\n",
        "        else:\n",
        "          if role[i][1] in NOUN_CODES:\n",
        "            new_word = lmtzr.lemmatize(word, 'n')\n",
        "            #x =  TreebankWordDetokenizer().detokenize(new_word)\n",
        "          else:\n",
        "            new_word = lmtzr.lemmatize(word)\n",
        "            #x =  TreebankWordDetokenizer().detokenize(new_word)\n",
        "    if len(new_word) > 1:\n",
        "      new_text.append(new_word)\n",
        "  final_text = ' '.join(new_text)\n",
        "  return final_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA_90bNfvcT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTraining[\"plot_vf\"] = dataTraining[\"plot_vf\"].apply(lematizacion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOn7QuhHxHgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTesting[\"plot_vf\"] = dataTesting[\"plot_vf\"].apply(lematizacion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkDYlJUhzTuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from nltk.corpus import stopwords\n",
        "#stop_words = stopwords.words('english')\n",
        "\n",
        "#dataTraining[\"plot\"] = dataTraining[\"plot\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "#dataTesting[\"plot\"] = dataTesting[\"plot\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDGpn0fcIgR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
        "\n",
        "le = MultiLabelBinarizer()\n",
        "y_genres = le.fit_transform(dataTraining['genres'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooL--olgIhq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot1=dataTraining['plot_vf']\n",
        "plot2=dataTesting['plot_vf']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KnfnVL9Gvuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A1=plot1.to_list()\n",
        "A2=plot2.to_list()\n",
        "A3=A1+A2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdnaw_m0KhSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "voca3 =[''.join(c for c in s if c not in string.punctuation) for s in A3]\n",
        "voca1 =[''.join(c for c in s if c not in string.punctuation) for s in A1]\n",
        "voca2=[''.join(c for c in s if c not in string.punctuation) for s in A2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9isBXTLkVYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "efe1be6b-30ae-4b98-c351-4a2ca4bd546d"
      },
      "source": [
        "X=[x.split() for x in voca1]\n",
        "len_=pd.Series([len(x) for x in X])\n",
        "len_.describe(percentiles=[.8,.9,.95,.975,.99]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    7895.000000\n",
              "mean      122.221406\n",
              "std        80.242849\n",
              "min         3.000000\n",
              "50%       106.000000\n",
              "80%       173.000000\n",
              "90%       230.000000\n",
              "95%       279.000000\n",
              "97.5%     318.650000\n",
              "99%       367.000000\n",
              "max      1648.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyNlM0b_MOwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 370"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv8X1I7I3GH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f1d2365-763f-47c4-bd3f-f8ceb8fa0b08"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(voca1)\n",
        "sequences = tokenizer.texts_to_sequences(voca1)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 34074 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmR6k2r9Li2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_trainG, X_testG, y_train_genresG, y_test_genresG = train_test_split(data, y_genres, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhi3_op6L4Mj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare embedding matrix\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wifYmv9CO1wX",
        "colab_type": "text"
      },
      "source": [
        "# DEFINICION DEL MODELO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggQ-AQ3Glvos",
        "colab_type": "text"
      },
      "source": [
        "## cargar librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pvpIs2cnycD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e50a4b-ed40-4cba-e1d0-3d6db724082b"
      },
      "source": [
        "!pip install livelossplot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/b0/d6d151eff47396561dda2a4a16e3a16f8b93b08eb3e39b5f0cd93a2e6875/livelossplot-0.5.2-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (49.1.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (7.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.13)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.11.2)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (20.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot) (1.1.1)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d_w41U3rfQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "7acb3d1b-ea82-4346-ac6b-9aaa41a43219"
      },
      "source": [
        "!pip install bpmll"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bpmll\n",
            "  Downloading https://files.pythonhosted.org/packages/05/b4/00504fabaefeaab0e22acf01638a8824ded6287d514b003cf8249dac555c/bpmll-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from bpmll) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (3.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.12.1)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (2.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (3.2.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (2.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->bpmll) (1.30.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow->bpmll) (49.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->bpmll) (3.1.0)\n",
            "Installing collected packages: bpmll\n",
            "Successfully installed bpmll-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB_ZFhZPSRb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from bpmll.bpmll import bp_mll_loss\n",
        "from keras.layers import Flatten\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTGP0jf01qa6",
        "colab_type": "text"
      },
      "source": [
        "## ejemplo kaggle Glove 1\n",
        "\n",
        "> Bloc con sangría\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxouhdcS1tr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "optimizador = keras.optimizers.Adam(lr=0.1) #0.001   \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=3))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(24, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizador, metrics=[tf.keras.metrics.AUC()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbTDqBPx3Z7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "cce57fd0-ff19-408f-be83-e73815dc10dd"
      },
      "source": [
        "history = model.fit(X_trainG, y_train_genresG, batch_size=128, epochs=50, verbose=1, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5684 samples, validate on 632 samples\n",
            "Epoch 1/50\n",
            "5684/5684 [==============================] - 10s 2ms/step - loss: 0.3448 - auc: 0.6971 - val_loss: 0.3152 - val_auc: 0.7362\n",
            "Epoch 2/50\n",
            "5684/5684 [==============================] - 9s 1ms/step - loss: 0.3074 - auc: 0.7457 - val_loss: 0.3085 - val_auc: 0.7514\n",
            "Epoch 3/50\n",
            "5684/5684 [==============================] - 9s 2ms/step - loss: 0.3073 - auc: 0.7543 - val_loss: 0.3068 - val_auc: 0.7571\n",
            "Epoch 4/50\n",
            "5684/5684 [==============================] - 9s 2ms/step - loss: 0.3069 - auc: 0.7594 - val_loss: 0.3176 - val_auc: 0.7602\n",
            "Epoch 5/50\n",
            "5684/5684 [==============================] - 9s 2ms/step - loss: 0.3079 - auc: 0.7608 - val_loss: 0.3156 - val_auc: 0.7616\n",
            "Epoch 6/50\n",
            "5684/5684 [==============================] - 9s 2ms/step - loss: 0.3079 - auc: 0.7622 - val_loss: 0.3135 - val_auc: 0.7629\n",
            "Epoch 7/50\n",
            "5684/5684 [==============================] - 9s 2ms/step - loss: 0.3096 - auc: 0.7631 - val_loss: 0.3090 - val_auc: 0.7635\n",
            "Epoch 8/50\n",
            "5684/5684 [==============================] - 8s 1ms/step - loss: 0.3061 - auc: 0.7638 - val_loss: 0.3065 - val_auc: 0.7645\n",
            "Epoch 9/50\n",
            "3072/5684 [===============>..............] - ETA: 3s - loss: 0.3133 - auc: 0.7646"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZsDQ4mM3x_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_genres = model.predict(X_testG)\n",
        "roc_auc_score(y_test_genresG, y_pred_genres, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSeHMTMDlYBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences1 = tokenizer.texts_to_sequences(voca2)\n",
        "data1 = pad_sequences(sequences1, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OItvjjfamVKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
        "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
        "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
        "\n",
        "y_pred_test_genres = model.predict(data1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJjAVBz2m8T2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "33286b86-731f-41b4-8c27-22e0d10a9d9d"
      },
      "source": [
        "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)\n",
        "res.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_Action</th>\n",
              "      <th>p_Adventure</th>\n",
              "      <th>p_Animation</th>\n",
              "      <th>p_Biography</th>\n",
              "      <th>p_Comedy</th>\n",
              "      <th>p_Crime</th>\n",
              "      <th>p_Documentary</th>\n",
              "      <th>p_Drama</th>\n",
              "      <th>p_Family</th>\n",
              "      <th>p_Fantasy</th>\n",
              "      <th>p_Film-Noir</th>\n",
              "      <th>p_History</th>\n",
              "      <th>p_Horror</th>\n",
              "      <th>p_Music</th>\n",
              "      <th>p_Musical</th>\n",
              "      <th>p_Mystery</th>\n",
              "      <th>p_News</th>\n",
              "      <th>p_Romance</th>\n",
              "      <th>p_Sci-Fi</th>\n",
              "      <th>p_Short</th>\n",
              "      <th>p_Sport</th>\n",
              "      <th>p_Thriller</th>\n",
              "      <th>p_War</th>\n",
              "      <th>p_Western</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.035560</td>\n",
              "      <td>0.043208</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>0.003074</td>\n",
              "      <td>0.225789</td>\n",
              "      <td>0.072154</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>0.513078</td>\n",
              "      <td>0.040691</td>\n",
              "      <td>0.095721</td>\n",
              "      <td>0.041303</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>0.166987</td>\n",
              "      <td>0.002951</td>\n",
              "      <td>0.014640</td>\n",
              "      <td>0.200472</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.485511</td>\n",
              "      <td>0.007209</td>\n",
              "      <td>0.004866</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>0.345063</td>\n",
              "      <td>0.004908</td>\n",
              "      <td>0.023391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.117986</td>\n",
              "      <td>0.010904</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.027202</td>\n",
              "      <td>0.108843</td>\n",
              "      <td>0.711218</td>\n",
              "      <td>0.003455</td>\n",
              "      <td>0.775623</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.002977</td>\n",
              "      <td>0.029711</td>\n",
              "      <td>0.010819</td>\n",
              "      <td>0.023189</td>\n",
              "      <td>0.009890</td>\n",
              "      <td>0.001935</td>\n",
              "      <td>0.065153</td>\n",
              "      <td>0.000793</td>\n",
              "      <td>0.053790</td>\n",
              "      <td>0.003842</td>\n",
              "      <td>0.005544</td>\n",
              "      <td>0.002227</td>\n",
              "      <td>0.659664</td>\n",
              "      <td>0.010013</td>\n",
              "      <td>0.034030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.096273</td>\n",
              "      <td>0.006461</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.087936</td>\n",
              "      <td>0.014675</td>\n",
              "      <td>0.884608</td>\n",
              "      <td>0.010657</td>\n",
              "      <td>0.943896</td>\n",
              "      <td>0.000715</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.274023</td>\n",
              "      <td>0.033222</td>\n",
              "      <td>0.005776</td>\n",
              "      <td>0.002375</td>\n",
              "      <td>0.001271</td>\n",
              "      <td>0.537351</td>\n",
              "      <td>0.000794</td>\n",
              "      <td>0.230259</td>\n",
              "      <td>0.006587</td>\n",
              "      <td>0.000577</td>\n",
              "      <td>0.003261</td>\n",
              "      <td>0.887100</td>\n",
              "      <td>0.006831</td>\n",
              "      <td>0.007255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.307982</td>\n",
              "      <td>0.183428</td>\n",
              "      <td>0.001471</td>\n",
              "      <td>0.009461</td>\n",
              "      <td>0.041886</td>\n",
              "      <td>0.042576</td>\n",
              "      <td>0.002071</td>\n",
              "      <td>0.713107</td>\n",
              "      <td>0.004486</td>\n",
              "      <td>0.021531</td>\n",
              "      <td>0.002604</td>\n",
              "      <td>0.026932</td>\n",
              "      <td>0.019063</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.000716</td>\n",
              "      <td>0.162462</td>\n",
              "      <td>0.000327</td>\n",
              "      <td>0.067342</td>\n",
              "      <td>0.255511</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.624968</td>\n",
              "      <td>0.049115</td>\n",
              "      <td>0.005090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.024649</td>\n",
              "      <td>0.031944</td>\n",
              "      <td>0.001513</td>\n",
              "      <td>0.001774</td>\n",
              "      <td>0.102751</td>\n",
              "      <td>0.022353</td>\n",
              "      <td>0.001047</td>\n",
              "      <td>0.346253</td>\n",
              "      <td>0.005952</td>\n",
              "      <td>0.071477</td>\n",
              "      <td>0.004157</td>\n",
              "      <td>0.001288</td>\n",
              "      <td>0.954867</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>0.389570</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.056675</td>\n",
              "      <td>0.246069</td>\n",
              "      <td>0.001518</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.671895</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.000829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   p_Action  p_Adventure  p_Animation  ...  p_Thriller     p_War  p_Western\n",
              "1  0.035560     0.043208     0.003329  ...    0.345063  0.004908   0.023391\n",
              "4  0.117986     0.010904     0.000209  ...    0.659664  0.010013   0.034030\n",
              "5  0.096273     0.006461     0.000051  ...    0.887100  0.006831   0.007255\n",
              "6  0.307982     0.183428     0.001471  ...    0.624968  0.049115   0.005090\n",
              "7  0.024649     0.031944     0.001513  ...    0.671895  0.000690   0.000829\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR1hJNY9nCmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res.to_csv('/content/drive/My Drive/Colab Notebooks/pred_genres_text_RF_V_9_52.csv', index_label='ID')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7QdzUSMQ4wC",
        "colab_type": "text"
      },
      "source": [
        "## Prueba XGBoost\n",
        "\n",
        "> Bloc con sangría"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml9_kt4bOwjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "clf = OneVsRestClassifier(XGBClassifier(max_depth=4,n_estimators=200,n_jobs=-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNXep98bU0fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.fit(X_trainG, y_train_genresG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iske55PgU9mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_genres = clf.predict(X_testG)\n",
        "roc_auc_score(y_test_genresG, y_pred_genres, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr5olheXWG7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}